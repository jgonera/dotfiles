#!/usr/bin/env bash

# Based on
# https://docs.unsloth.ai/basics/tutorials-how-to-fine-tune-and-run-llms/devstral-how-to-run-and-fine-tune
# Use custom chat template file (from original Devstral) because of a bug in
# Unsloth's version.

DIR=$(cd "$(dirname "$0")"; pwd)

llama-server \
    -hf unsloth/Devstral-Small-2507-GGUF:UD-Q4_K_XL \
    --port 11434 \
    --threads -1 \
    --ctx-size 131072 \
    --cache-type-k q8_0 \
    --cache-type-v q8_0 \
    --flash-attn \
    --n-gpu-layers 41 \
    --seed 3407 \
    --prio 2 \
    --temp 0.15 \
    --repeat-penalty 1.0 \
    --min-p 0.01 \
    --top-k 64 \
    --top-p 0.95 \
    --jinja \
    --verbose \
    --chat-template-file "$DIR/devstral.jinja"
    # -hf mistralai/Devstral-Small-2507_gguf:Q4_K_M \
